# Titanic MLOps Pipeline with AWS, MLflow, and Docker

## ğŸ§­ Overview

This project provides a complete, end-to-end MLOps pipeline for the classic Titanic survival prediction problem. It demonstrates best practices for building a modular, scalable, and reproducible machine learning system using modern tools.

The pipeline fetches the Titanic dataset, preprocesses it, trains multiple models (a scikit-learn RandomForest and a PyTorch MLP), tracks experiments with MLflow, and stores artifacts in AWS S3. It is designed to be run in a containerized environment using Docker. Additionally, it includes an optional AWS Lambda function for serving model inference.

## âœ¨ Core Components

*   **Data Management (AWS S3)**: The Titanic dataset is stored in and loaded from an S3 bucket, ensuring a single source of truth and decoupling data from the training code.
*   **Training Pipeline (`src/pipeline.py`)**: A flexible, dependency-injected pipeline that handles data loading, preprocessing, and model training. It is designed to accept different training strategies.
*   **Model Training (`src/strategies.py`)**: Implements two distinct training strategies:
    *   A `RandomForestClassifier` from scikit-learn.
    *   A multi-layer perceptron (MLP) using PyTorch.
*   **Experiment Tracking (MLflow)**: All training runs, parameters, metrics, and model artifacts are logged to an MLflow Tracking Server, which can be run locally via Docker Compose.
*   **Containerization (Docker)**: The entire environment, including the MLflow server and the training pipeline, is containerized with Docker and orchestrated with Docker Compose for easy setup and execution.
*   **Inference (AWS Lambda)**: An optional Lambda function (`lambda/handler.py`) is provided to demonstrate how a trained model could be deployed for serverless inference.

---

## ğŸ–¼ï¸ Screenshots

Here is a screenshot of the MLflow UI showing the experiment runs:

![MLflow Experiments](screenshots/Screenshot%202025-08-08%20at%2019.49.00.png)

And here is a view of the artifacts logged for a specific run:

![MLflow Artifacts](screenshots/Screenshot%202025-08-08%20at%2019.49.36.png)

---

## ğŸ—‚ï¸ Project Structure

```
/Users/valba/Documents/mlflow-hw-08/
â”œâ”€â”€â”€.dockerignore
â”œâ”€â”€â”€.gitignore
â”œâ”€â”€â”€docker-compose.yml
â”œâ”€â”€â”€Dockerfile
â”œâ”€â”€â”€Dockerfile.mlflow
â”œâ”€â”€â”€LICENSE
â”œâ”€â”€â”€README.md
â”œâ”€â”€â”€requirements.txt
â”œâ”€â”€â”€.git/...
â”œâ”€â”€â”€docs/
â”‚   â””â”€â”€â”€setup_guide.md
â”œâ”€â”€â”€lambda/
â”‚   â”œâ”€â”€â”€handler.py
â”‚   â””â”€â”€â”€requirements.txt
â”œâ”€â”€â”€mlflow_db/
â”œâ”€â”€â”€mlruns/...
â”œâ”€â”€â”€screenshots/
â””â”€â”€â”€src/
    â”œâ”€â”€â”€__init__.py
    â”œâ”€â”€â”€main.py
    â”œâ”€â”€â”€model.py
    â”œâ”€â”€â”€pipeline.py
    â”œâ”€â”€â”€strategies.py
    â”œâ”€â”€â”€titanic.csv
    â”œâ”€â”€â”€train_utils.py
    â””â”€â”€â”€__pycache__/
```

---

## ğŸ”§ Setup Instructions

### 1. AWS Configuration

Set up a free-tier AWS account and create an S3 bucket (e.g., `va-titanic`).
Add credentials to a `.env` file in the root directory:

```env
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
AWS_DEFAULT_REGION=us-east-1
```

### 2. Upload Dataset to S3

Artifacts appear in:
`s3://$MLFLOW_ARTIFACTS_BUCKET/mlflow-artifacts/...`

Dataset is stored at:
`s3://$MLFLOW_ARTIFACTS_BUCKET/$DATA_S3_PREFIX/titanic.csv`
---

## ğŸš€ Usage

### Running the Training Pipeline

To run the entire pipeline, including the MLflow Tracking Server, use Docker Compose:

```bash
docker-compose up --build
```

This command will:
1.  Build the Docker images for the MLflow server and the training environment.
2.  Start the MLflow server, which will be accessible at `http://localhost:5000`.
3.  Run the training pipeline defined in `src/main.py`. The script will:
    *   Ensure the Titanic dataset is in your S3 bucket.
    *   Train both the RandomForest and PyTorch MLP models.
    *   Log all experiments, parameters, and metrics to the MLflow server.



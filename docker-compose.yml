services:

  mlflow:
    build:
      context: .
      dockerfile: Dockerfile.mlflow
      args:
        MLFLOW_VERSION: ${MLFLOW_VERSION}
    container_name: mlflow-server
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}
    ports:
      - "5050:5000"
    volumes:
      - ./mlflow_db:/mlflow/db
    command: >
      mlflow server --backend-store-uri sqlite:////mlflow/db/mlflow.db --artifacts-destination s3://${MLFLOW_ARTIFACTS_BUCKET}/mlflow-artifacts --host 0.0.0.0 --port 5000

  trainer:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: titanic-trainer
    depends_on:
      - mlflow
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}
      - GIT_PYTHON_REFRESH=quiet
      - GIT_PYTHON_GIT_EXECUTABLE=/usr/bin/git
      - DATASET_LOCAL_PATH=/app/titanic.csv
      - PYTHONUNBUFFERED=1
    volumes:
      - .:/app
    command: python main.py

  lambda:
    platform: "linux/amd64"
    build:
      context: .
      dockerfile: Dockerfile.lambda   # uses the AWS Lambda base image
    container_name: titanic-lambda
    environment:
      # S3 access for downloading the bundle
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}

      # Where the bundle is stored (must match what training exported)
      - MODEL_BUCKET=${MODEL_BUCKET:-${MLFLOW_ARTIFACTS_BUCKET}}
      - MODEL_BASE=${MODEL_BASE:-serving/random_forest}
    ports:
      - "9000:8080"   # local port 9000 â†’ lambda runtime 8080
    # optional: start only when you want to test lambda
    # profiles: ["lambda"]